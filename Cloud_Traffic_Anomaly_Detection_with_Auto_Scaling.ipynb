{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiddarthaNanuvala/Cloud-Traffic-Anomaly-Detection-with-Auto-Scaling/blob/main/Cloud_Traffic_Anomaly_Detection_with_Auto_Scaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scikit-learn xgboost lightgbm imbalanced-learn scipy mlxtend umap-learn\n"
      ],
      "metadata": {
        "id": "MYcKa0RRDa56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f8b317-f244-49c5-df86-5599debb9001"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping numpy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping scikit-learn as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping xgboost as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping lightgbm as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping imbalanced-learn as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping scipy as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping mlxtend as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping umap-learn as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a5_1vIdY2e7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab12a0bd-146a-4cbe-cdba-c4a7d47049e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'unsw-nb15-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/unsw-nb15-dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"programmer3/unsw-nb15-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "import pandas as pd\n",
        "\n",
        "# Find all relevant CSV files in the downloaded dataset folder\n",
        "csvs = glob.glob('/root/.cache/kagglehub/datasets/programmer3/unsw-nb15-dataset/versions/2/**/*.csv', recursive=True)\n",
        "print(len(csvs), 'CSV files found')\n",
        "for p in csvs[:10]:\n",
        "    print(p)\n",
        "\n",
        "# Load and preview the first CSV file\n",
        "df = pd.read_csv(csvs[0])\n",
        "print('Shape:', df.shape)\n",
        "print('Columns:', list(df.columns)[:20], '...')\n",
        "print(df.head(3))\n"
      ],
      "metadata": {
        "id": "2geGb0S83fhj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "425bd91f-c0f0-4a0b-dae5-1499148c15b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.random'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1182272232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Find all relevant CSV files in the downloaded dataset folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcsvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.cache/kagglehub/datasets/programmer3/unsw-nb15-dataset/versions/2/**/*.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.random'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify possible label and category columns\n",
        "label_col_candidates = [c for c in df.columns if c.lower() in ['label', 'is_attack', 'class', 'binary_label']]\n",
        "cat_col_candidates = [c for c in df.columns if 'attack' in c.lower() and 'cat' in c.lower()]\n",
        "print('Binary candidates:', label_col_candidates)\n",
        "print('Attack category candidates:', cat_col_candidates)\n",
        "\n",
        "BINARY_COL = label_col_candidates[0]\n",
        "ATTACK_COL = cat_col_candidates[0] if cat_col_candidates else None\n",
        "\n",
        "# Normalize binary label to 0/1\n",
        "df['y_bin'] = (df[BINARY_COL].astype(int) > 0).astype(int)\n",
        "\n",
        "# Normalize multiclass (optional)\n",
        "if ATTACK_COL:\n",
        "    df['y_cat'] = df[ATTACK_COL].fillna('Benign').replace({'-': 'Benign'})\n",
        "print(df[['y_bin']].head())\n",
        "if ATTACK_COL:\n",
        "    print(df[['y_cat']].head())\n"
      ],
      "metadata": {
        "id": "W3Iyzf3Z3y8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify pure identifier, network, and timing columns\n",
        "id_like = [c for c in df.columns if any(k in c.lower() for k in ['id', 'flowid'])]\n",
        "net_like = [c for c in df.columns if c.lower() in ['srcip', 'dstip', 'sport', 'dsport']]\n",
        "time_like = [c for c in df.columns if 'time' in c.lower() or c.lower() in ['timestamp', 'stime', 'ltime']]\n",
        "print('id_like:', id_like)\n",
        "print('net_like:', net_like)\n",
        "print('time_like:', time_like)\n"
      ],
      "metadata": {
        "id": "2JQTjj7a4GHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check for missing values, duplicates, and class balance\n",
        "na_counts = df.isna().sum().sort_values(ascending=False)\n",
        "print('Top NA columns:\\n', na_counts.head(15))\n",
        "dup_count = df.duplicated().sum()\n",
        "print('Duplicate rows:', dup_count)\n",
        "\n",
        "# Binary class distribution and attack categories\n",
        "print('y_bin value counts:\\n', df['y_bin'].value_counts(dropna=False))\n",
        "if 'y_cat' in df:\n",
        "    print('Top attack categories:\\n', df['y_cat'].value_counts().head(10))\n",
        "\n",
        "# Numeric columns summary\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print('Numeric columns:', len(num_cols))\n",
        "print(df[num_cols].describe().T.head(12))\n"
      ],
      "metadata": {
        "id": "4sTOVy5N4L5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scikit-learn xgboost lightgbm imbalanced-learn\n"
      ],
      "metadata": {
        "id": "tOwmdT68Aplk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scikit-learn xgboost lightgbm imbalanced-learn scipy mlxtend umap-learn\n"
      ],
      "metadata": {
        "id": "iGvulI2hA_kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5 scikit-learn==1.2.2 xgboost==1.7.6 lightgbm==4.1.0 imbalanced-learn==0.9.1 scipy==1.11.4\n"
      ],
      "metadata": {
        "id": "omSph_A3Atvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Drop target columns for feature set\n",
        "X_num = df.drop(columns=['label', 'attack_cat', 'y_bin', 'y_cat'], errors='ignore').select_dtypes(include=[np.number]).copy()\n",
        "y = df['y_bin']\n",
        "\n",
        "print('Numeric features:', X_num.shape[1])\n",
        "print('First few feature columns:', X_num.columns.tolist()[:10])\n",
        "\n",
        "# Train/test split and random forest model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, digits=4))\n"
      ],
      "metadata": {
        "id": "BVFZ8szv4aYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually balance dataset: equal records per class\n",
        "n_benign = df[df['y_bin']==0].shape[0]\n",
        "n_attack = n_benign  # Same number for balance\n",
        "\n",
        "benign_sample = df[df['y_bin'] == 0]\n",
        "attack_sample = df[df['y_bin'] == 1].sample(n=n_attack, random_state=42)\n",
        "\n",
        "sample = pd.concat([benign_sample, attack_sample]).sample(frac=1, random_state=42)  # shuffle\n",
        "\n",
        "# Save files\n",
        "sample.to_csv('unsw_stage1_sample.csv', index=False)\n",
        "pd.Series(X_num.columns).to_csv('unsw_stage1_feature_columns.csv', index=False)\n",
        "\n",
        "import os\n",
        "print(\"Files saved:\", os.listdir())\n"
      ],
      "metadata": {
        "id": "uLVYEl2Q5UiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the dataset sample and the features file\n",
        "files.download('unsw_stage1_sample.csv')\n",
        "files.download('unsw_stage1_feature_columns.csv')\n"
      ],
      "metadata": {
        "id": "T4bSNzn55YKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load balanced sample (created in Stage 1)\n",
        "df = pd.read_csv('unsw_stage1_sample.csv')\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(df.head(3))\n"
      ],
      "metadata": {
        "id": "vaCYdLE1RLiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use numeric features for modeling\n",
        "X = df.drop(columns=['label','attack_cat','y_bin','y_cat'], errors='ignore').select_dtypes(include=['number']).copy()\n",
        "y = df['y_bin'].copy()\n",
        "print(\"Number of features:\", X.shape[1])\n"
      ],
      "metadata": {
        "id": "vSpo97qBRSR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified split (70% train, 15% val, 15% test)\n",
        "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=0.1765, random_state=42, stratify=y_tv)\n",
        "print(\"Train/Val/Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
        "print(\"Train class distribution:\", y_train.value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "r9X0MchcRVJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def eval_metrics(y_true, y_pred, y_proba=None):\n",
        "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0, 1])\n",
        "    macro_f1 = f1.mean()\n",
        "    roc = roc_auc_score(y_true, y_proba) if y_proba is not None else None\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    return {\n",
        "        'prec_0': p[0], 'rec_0': r[0], 'f1_0': f1[0],\n",
        "        'prec_1': p[1], 'rec_1': r[1], 'f1_1': f1[1],\n",
        "        'macro_f1': macro_f1, 'roc_auc': roc, 'cm': cm\n",
        "    }\n",
        "\n",
        "def pick_threshold(y_true, proba, target='f1_1'):\n",
        "    thresholds = np.linspace(0.1, 0.9, 17)\n",
        "    best_t, best_score = 0.5, -1\n",
        "    for t in thresholds:\n",
        "        pred = (proba >= t).astype(int)\n",
        "        m = eval_metrics(y_true, pred, proba)\n",
        "        score = m[target]\n",
        "        if score > best_score:\n",
        "            best_score, best_t = score, t\n",
        "    return best_t\n"
      ],
      "metadata": {
        "id": "i-shyxbdRY2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipelines = {\n",
        "    'LR_balanced': Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=200, class_weight='balanced', n_jobs=-1))\n",
        "    ]),\n",
        "    'RF_balanced': RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced_subsample', n_jobs=-1),\n",
        "}\n",
        "print(\"Pipelines ready:\", list(pipelines.keys()))\n"
      ],
      "metadata": {
        "id": "Oa9mZ27PRbo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose model pipeline\n",
        "name = 'RF_balanced'  # Use 'LR_balanced' for logistic regression\n",
        "model = pipelines[name]\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "proba_val = model.predict_proba(X_val)[:,1]\n",
        "t_star = pick_threshold(y_val, proba_val, target='f1_1')\n",
        "y_val_pred = (proba_val >= t_star).astype(int)\n",
        "\n",
        "metrics_val = eval_metrics(y_val, y_val_pred, proba_val)\n",
        "print(f\"{name} Validation Metrics:\", {k: round(float(v),4) if not isinstance(v,np.ndarray) else v.tolist() for k,v in metrics_val.items()})\n",
        "print(\"Optimal probability threshold:\", t_star)\n"
      ],
      "metadata": {
        "id": "Z91GW6M4Red8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "proba_test = model.predict_proba(X_test)[:,1]\n",
        "y_test_pred = (proba_test >= t_star).astype(int)\n",
        "test_metrics = eval_metrics(y_test, y_test_pred, proba_test)\n",
        "print(\"Test Metrics:\", {k: round(float(v),4) if not isinstance(v,np.ndarray) else v.tolist() for k,v in test_metrics.items()})\n"
      ],
      "metadata": {
        "id": "BDNidcijRwOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'LR_balanced'\n",
        "model = pipelines[name]\n",
        "model.fit(X_train, y_train)\n",
        "proba_val = model.predict_proba(X_val)[:,1]\n",
        "t_star_lr = pick_threshold(y_val, proba_val, target='f1_1')\n",
        "y_val_pred = (proba_val >= t_star_lr).astype(int)\n",
        "metrics_val_lr = eval_metrics(y_val, y_val_pred, proba_val)\n",
        "print(f\"{name} Validation Metrics:\", {k: round(float(v),4) if not isinstance(v,np.ndarray) else v.tolist() for k,v in metrics_val_lr.items()})\n",
        "print(\"Optimal probability threshold:\", t_star_lr)\n"
      ],
      "metadata": {
        "id": "oOO3Vw0SRyA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
        "print(\"After SMOTE:\", dict(zip(*np.unique(y_train_sm, return_counts=True))))\n",
        "model.fit(X_train_sm, y_train_sm)\n",
        "# Continue with validation and test as before\n"
      ],
      "metadata": {
        "id": "Saa27M2zSRqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_class_metrics(metrics, title):\n",
        "    labels = ['Benign', 'Attack']\n",
        "    precision = [metrics['prec_0'], metrics['prec_1']]\n",
        "    recall = [metrics['rec_0'], metrics['rec_1']]\n",
        "    f1 = [metrics['f1_0'], metrics['f1_1']]\n",
        "    x = range(len(labels))\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.bar(x, precision, width=0.2, label='Precision', align='center')\n",
        "    plt.bar([i+0.2 for i in x], recall, width=0.2, label='Recall', align='center')\n",
        "    plt.bar([i+0.4 for i in x], f1, width=0.2, label='F1', align='center')\n",
        "    plt.xticks([i+0.2 for i in x], labels)\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_class_metrics(metrics_val, \"Validation Metrics\")\n"
      ],
      "metadata": {
        "id": "TTGQPZzYSXJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_val, proba_val)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(fpr, tpr, label='ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (Validation)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l6jPqkzdScNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost lightgbm scikit-learn==1.2.2\n"
      ],
      "metadata": {
        "id": "N73au4AlTDdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    scale_pos_weight=1, # or set = n_benign/n_attack if imbalanced\n",
        "    random_state=42,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric=\"logloss\"\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "proba_val_xgb = xgb_model.predict_proba(X_val)[:,1]\n",
        "t_star_xgb = pick_threshold(y_val, proba_val_xgb, target='f1_1')\n",
        "y_val_pred_xgb = (proba_val_xgb >= t_star_xgb).astype(int)\n",
        "metrics_val_xgb = eval_metrics(y_val, y_val_pred_xgb, proba_val_xgb)\n",
        "print(\"XGBoost Validation Metrics:\", {k: round(float(v),4) if not isinstance(v,np.ndarray) else v.tolist() for k,v in metrics_val_xgb.items()})\n",
        "print(\"Optimal threshold (XGB):\", t_star_xgb)\n"
      ],
      "metadata": {
        "id": "WCNE-lDeTE7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}